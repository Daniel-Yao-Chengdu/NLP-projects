{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train KG embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "HbemiIAs4VCC"
      },
      "cell_type": "markdown",
      "source": [
        "# 1.0 Knowledge Graph Embeddings Introduction\n",
        "\n",
        "Word embeddings aim at capturing the meaning of words based on very large corpora; however, there are decades of experience and approaches that have tried to capture this meaning by structuring knowledge into semantic nets, ontologies and graphs. \n",
        "\n",
        "|         | Neural           | Symbolic  |\n",
        "| ------------- |-------------| -----|\n",
        "| **representation**      | vectors | symbols (URIs) |\n",
        "| **input**               | large corpora   | human editors (Knowledge engineers) |\n",
        "| **interpretability**      | linked to model and training dataset      |   requires understanding of schema  |\n",
        "| **alignability**    | parallel (annotated) corpora | heuristics + manual |\n",
        "| **composability** | combine vectors | merge graphs | \n",
        "| **extensibility**   | fixed vocabulary | need to know how to link new nodes |\n",
        "| **certainty**        | fuzzy | exact |\n",
        "| **debugability**  | 'fix' training data? | edit graph |\n",
        "\n",
        "In recent years, many new approaches have been proposed to derive 'neural' representations for existing knowledge graphs. Think of this as trying to capture the knowledge encoded in the KG to make it easier to use this in deep learning models.\n",
        "\n",
        " - [TransE (2013)](http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf): try to assign an embedding to nodes and relations, so that $h + r$ is close to $t$, where $h$ and $t$ are nodes in the graph and $r$ is an edge. In the RDF world, this is simply an RDF triple where $h$ is the subject $r$ is the property and $t$ is the object of the triple.\n",
        " - [HolE (2016)](http://arxiv.org/abs/1510.04935): Variant of TransE, but uses a different operator (circular correlation) to represent pairs of entities.\n",
        " - [RDF2Vec(2016)](https://ub-madoc.bib.uni-mannheim.de/41307/1/Ristoski_RDF2Vec.pdf): applies word2vec to random walks on an RDF graph (essentially paths or sequences of nodes in the graph). \n",
        " - [Graph convolutions(2018)](http://arxiv.org/abs/1703.06103): apply convolutional operations on graphs to learn the embeddings.\n",
        " - [Neural message passing(2018)](https://arxiv.org/abs/1704.01212): merges two strands of research on KG embeddings: recurrent and convolutional approaches.\n",
        " \n",
        "For more background: [Nickel, M., Murphy, K., Tresp, V., & Gabrilovich, E. (2016). A review of relational machine learning for knowledge graphs. Proceedings of the IEEE, 104(1), 11–33. https://doi.org/10.1109/JPROC.2015.2483592](http://www.dbs.ifi.lmu.de/~tresp/papers/1503.00759v3.pdf) provides a good overview (up to 2016).\n",
        "\n",
        "Steps:\n",
        "  \n",
        "  0. Choose (or implement) a KG embedding algorithm\n",
        "  1. Convert the KG into format required by embedding algorithm\n",
        "  2. Execute the training\n",
        "  3. Evaluate/inspect results"
      ]
    },
    {
      "metadata": {
        "id": "DHfn9HX6__Wt"
      },
      "cell_type": "markdown",
      "source": [
        "# 2.0 Install algorithms and import dataset"
      ]
    },
    {
      "metadata": {
        "id": "LB3dpgvCAC_U"
      },
      "cell_type": "markdown",
      "source": [
        "Choose embedding algorithm: HolE\n",
        "\n",
        "We will use an [existing implementation of the `HolE` algorithm available on GitHub](https://github.com/mnick/holographic-embeddings). "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###2.1.1 Install `scikit-kge` package\n",
        "\n",
        "The `holographic-embeddings` repo is actually just a wrapper around `scikit-kge` or [SKGE](https://github.com/mnick/scikit-kge), a library that implements a few KG embedding algorithms. First, we need to install `scikit-kge` as a library in our environment. Execute the following cells to clone the repository and install the library."
      ],
      "metadata": {
        "id": "72IbeAsH5VYd"
      }
    },
    {
      "metadata": {
        "id": "-xScJEUjoM3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01772ed8-1d6f-46e6-f2bc-2a4aeb731810"
      },
      "cell_type": "code",
      "source": [
        "# make sure we are in the right folder to perform the git clone\n",
        "%cd /content/\n",
        "!git clone https://github.com/hybridNLP2018/scikit-kge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'scikit-kge'...\n",
            "remote: Enumerating objects: 116, done.\u001b[K\n",
            "remote: Total 116 (delta 0), reused 0 (delta 0), pack-reused 116\u001b[K\n",
            "Receiving objects: 100% (116/116), 25.32 KiB | 8.44 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "D-hV6dZN3RXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd5a953-5c7b-4636-d4d9-13ed6c287f66"
      },
      "cell_type": "code",
      "source": [
        "%cd scikit-kge\n",
        "# install a dependency of scikit-kge on the colaboratory environment, needed to correclty build scikit-kge\n",
        "!pip install nose\n",
        "# now build a source distribution for the project\n",
        "!python setup.py sdist\n",
        "#which we can install on the local environment by using pip, the python package manager.\n",
        "!pip install dist/scikit-kge-0.1.tar.gz\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/scikit-kge\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 23.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: nose\n",
            "Successfully installed nose-1.3.7\n",
            "setuptools module not found.\n",
            "Install setuptools if you want to enable 'python setup.py develop'.\n",
            "setup.py:77: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\n",
            "\u001b[39mrunning sdist\u001b[0m\n",
            "\u001b[39mrunning egg_info\u001b[0m\n",
            "/usr/lib/python3.7/distutils/dist.py:985: UserWarning: \n",
            "`build_src` is being run, this may lead to missing\n",
            "files in your sdist!  You want to use distutils.sdist\n",
            "instead of the setuptools version:\n",
            "\n",
            "    from distutils.command.sdist import sdist\n",
            "    cmdclass={'sdist': sdist}\"\n",
            "\n",
            "See numpy's setup.py or gh-7131 for details.\n",
            "  cmd_obj.run()\n",
            "\u001b[39mrunning build_src\u001b[0m\n",
            "\u001b[39mbuild_src\u001b[0m\n",
            "\u001b[39mcreating scikit_kge.egg-info\u001b[0m\n",
            "\u001b[39mwriting scikit_kge.egg-info/PKG-INFO\u001b[0m\n",
            "\u001b[39mwriting dependency_links to scikit_kge.egg-info/dependency_links.txt\u001b[0m\n",
            "\u001b[39mwriting top-level names to scikit_kge.egg-info/top_level.txt\u001b[0m\n",
            "\u001b[39mwriting manifest file 'scikit_kge.egg-info/SOURCES.txt'\u001b[0m\n",
            "\u001b[39madding license file 'LICENSE'\u001b[0m\n",
            "\u001b[39mwriting manifest file 'scikit_kge.egg-info/SOURCES.txt'\u001b[0m\n",
            "\u001b[39mrunning check\u001b[0m\n",
            "\u001b[39mcreating scikit-kge-0.1\u001b[0m\n",
            "\u001b[39mcreating scikit-kge-0.1/skge\u001b[0m\n",
            "\u001b[39mcreating scikit-kge-0.1/scikit_kge.egg-info\u001b[0m\n",
            "\u001b[39mcopying files to scikit-kge-0.1...\u001b[0m\n",
            "\u001b[39mcopying LICENSE -> scikit-kge-0.1\u001b[0m\n",
            "\u001b[39mcopying README.md -> scikit-kge-0.1\u001b[0m\n",
            "\u001b[39mcopying setup.py -> scikit-kge-0.1\u001b[0m\n",
            "\u001b[39mcopying ./skge/__init__.py -> scikit-kge-0.1/./skge\u001b[0m\n",
            "\u001b[39mcopying ./skge/actfun.py -> scikit-kge-0.1/./skge\u001b[0m\n",
            "\u001b[39mcopying ./skge/base.py -> scikit-kge-0.1/./skge\u001b[0m\n",
            "\u001b[39mcopying ./skge/hole.py -> scikit-kge-0.1/./skge\u001b[0m\n",
            "\u001b[39mcopying ./skge/param.py -> scikit-kge-0.1/./skge\u001b[0m\n",
            "\u001b[39mcopying ./skge/rescal.py -> scikit-kge-0.1/./skge\u001b[0m\n",
            "\u001b[39mcopying ./skge/sample.py -> scikit-kge-0.1/./skge\u001b[0m\n",
            "\u001b[39mcopying ./skge/transe.py -> scikit-kge-0.1/./skge\u001b[0m\n",
            "\u001b[39mcopying ./skge/util.py -> scikit-kge-0.1/./skge\u001b[0m\n",
            "\u001b[39mcopying ./skge/version.py -> scikit-kge-0.1/./skge\u001b[0m\n",
            "\u001b[39mcopying scikit_kge.egg-info/PKG-INFO -> scikit-kge-0.1/scikit_kge.egg-info\u001b[0m\n",
            "\u001b[39mcopying scikit_kge.egg-info/SOURCES.txt -> scikit-kge-0.1/scikit_kge.egg-info\u001b[0m\n",
            "\u001b[39mcopying scikit_kge.egg-info/dependency_links.txt -> scikit-kge-0.1/scikit_kge.egg-info\u001b[0m\n",
            "\u001b[39mcopying scikit_kge.egg-info/top_level.txt -> scikit-kge-0.1/scikit_kge.egg-info\u001b[0m\n",
            "\u001b[39mWriting scikit-kge-0.1/setup.cfg\u001b[0m\n",
            "\u001b[39mcreating dist\u001b[0m\n",
            "\u001b[39mCreating tar archive\u001b[0m\n",
            "\u001b[39mremoving 'scikit-kge-0.1' (and everything under it)\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./dist/scikit-kge-0.1.tar.gz\n",
            "Building wheels for collected packages: scikit-kge\n",
            "  Building wheel for scikit-kge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-kge: filename=scikit_kge-0.1-py3-none-any.whl size=12523 sha256=5a8be1bd21a06609b3043ca65132e2820b3cd63da63f09e940d8ab7b9094c658\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/3c/22/5f6e501951806b092a4f4598005c0b083869a943f54d406f51\n",
            "Successfully built scikit-kge\n",
            "Installing collected packages: scikit-kge\n",
            "Successfully installed scikit-kge-0.1\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.2 Install holographic algorithm"
      ],
      "metadata": {
        "id": "GkLOvbw83acQ"
      }
    },
    {
      "metadata": {
        "id": "WizYMgrc4rTJ"
      },
      "cell_type": "markdown",
      "source": [
        "Install and inspect `holographic_embeddings` repo\n",
        "Now that `skge` is installed on this environment, we are ready to clone the [holographic-embeddings](https://github.com/mnick/holographic-embeddings) repository, which will enable us to train `HolE` embeddings."
      ]
    },
    {
      "metadata": {
        "id": "VSZaNq4pFr1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c811b261-85fb-41c5-f454-8b1d9b61ed12"
      },
      "cell_type": "code",
      "source": [
        "# let's go back to the main \\content folder and clone the holE repo\n",
        "%cd /content/\n",
        "!git clone https://github.com/mnick/holographic-embeddings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'holographic-embeddings'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Total 37 (delta 0), reused 0 (delta 0), pack-reused 37\u001b[K\n",
            "Unpacking objects: 100% (37/37), done.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "d1Yoa6zR6mpA"
      },
      "cell_type": "markdown",
      "source": [
        "Training arguments"
      ]
    },
    {
      "metadata": {
        "id": "E9nlPWCHO1cW"
      },
      "cell_type": "code",
      "source": [
        "%less holographic-embeddings/run_hole_wn18.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qeE8XuMM7p4x"
      },
      "cell_type": "markdown",
      "source": [
        "You should see a section on the bottom of the screen with the contents of the `run_hole_wn18.sh` file. The main execution is:\n",
        "\n",
        "```\n",
        "python kg/run_hole.py --fin data/wn18.bin \\\n",
        "       --test-all 50 --nb 100 --me 500 \\\n",
        "       --margin 0.2 --lr 0.1 --ncomp 150\n",
        "```\n",
        "\n",
        "which is just executing the `kg/run_hole.py` script on the input data `data/wn18.bin` and passing various arguments to control how to train and produce the embeddings:\n",
        "\n",
        "  * `me`: states the number of epochs to train for (i.e. number of times to go through the input dataset)\n",
        "  * `ncomp`: specifies the dimension of the embeddings, each embedding will be a vector of 150 dimensions\n",
        "  * `nb`: number of batches\n",
        "  * `test-all`: specifies how often to run validation of the intermediate embeddings. In this case, every 50 epochs."
      ]
    },
    {
      "metadata": {
        "id": "Cmb4X3kFC79i"
      },
      "cell_type": "markdown",
      "source": [
        "# 3.0 Convert our dataset to required input\n",
        "SKGE requires a graph to be represented as a serialized python dictionary with the following structure:\n",
        "  * `relations`: a list of relation names (the named edges in the graph)\n",
        "  * `entities`:  a list of entity names (the nodes in the graph), \n",
        "  * `train_subs`: a list of triples of the form `(head_id, tail_id, rel_id)`, where `head_id` and `tail_id` refer to the index in the `entities`list and `rel_id` refers to the index in the `relations` list. This is the list of triples that will be used to train the embeddings.\n",
        "  * `valid_subs`: a list of triples of the same form as `train_subs`. These are used to validate the embeddings during training (and thus to tune hyperparameters).\n",
        "  * `test_subs`: a list of triples of the same form as `test_subs`.  These are used to test the learned embeddings."
      ]
    },
    {
      "metadata": {
        "id": "f604qgU6M_WV"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have methods for generating lists of triples, we can generate the input dictionary and serialise it. We need to:\n",
        "  * create our lists of entities and relations, \n",
        "  * derive a map from entity and relation names to ids\n",
        "  * generate the triples\n",
        "  * split the triples into training, validation and test subsets\n",
        "  * write the python dict to a serialised file\n",
        "  \n",
        "We implement this in the following method:"
      ]
    },
    {
      "metadata": {
        "id": "aZ8tLDQPPPL7"
      },
      "cell_type": "code",
      "source": [
        "# data.bin file is created by myself, I can explore it\n",
        "inputs='/content/holographic-embeddings/data/data.bin'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X8MCByxEDHpE"
      },
      "cell_type": "markdown",
      "source": [
        "# 4.0 Learn the embeddings\n",
        "Now, we will use the WordNet 3.0 dataset to learn embeddings for both synsets and lemmas. Since this is fairly slow, we only train for 2 epochs, which can take up to 10 minutes (In the exercises at the end of this notebook, we provide a link to download pre-computed embeddings which have been trained for 500 epochs.)"
      ]
    },
    {
      "metadata": {
        "id": "QDMTf-8ISm2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89227e3c-2f01-4a95-d9c2-782833714b2f"
      },
      "cell_type": "code",
      "source": [
        "outputs='/content/output_embeddings.bin'\n",
        "holE_dim=150\n",
        "num_epochs=50\n",
        "num_batches=100\n",
        "lr=0.08\n",
        "!python /content/holographic-embeddings/kg/run_hole.py --fin {inputs} --fout {outputs} \\\n",
        "  --nb {num_batches} --me {num_epochs} --margin 0.2 --lr {lr} --ncomp {holE_dim}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:EX-KG:[ 10] VALID: MRR = 0.91/0.95, Mean Rank = 28.82/28.64, Hits@10 = 96.28/96.62\n",
            "DEBUG:EX-KG:FMRR valid = 0.947005, best = -1.000000\n",
            "INFO:EX-KG:[ 10] TEST: MRR = 0.92/0.96, Mean Rank = 23.61/23.42, Hits@10 = 97.28/97.83\n",
            "INFO:EX-KG:[ 11] time = 0s, violations = 125\n",
            "INFO:EX-KG:[ 12] time = 0s, violations = 98\n",
            "INFO:EX-KG:[ 13] time = 0s, violations = 92\n",
            "INFO:EX-KG:[ 14] time = 0s, violations = 99\n",
            "INFO:EX-KG:[ 15] time = 0s, violations = 96\n",
            "INFO:EX-KG:[ 16] time = 0s, violations = 86\n",
            "INFO:EX-KG:[ 17] time = 0s, violations = 52\n",
            "INFO:EX-KG:[ 18] time = 0s, violations = 72\n",
            "INFO:EX-KG:[ 19] time = 0s, violations = 61\n",
            "INFO:EX-KG:[ 20] time = 0s, violations = 69\n",
            "INFO:EX-KG:[ 20] VALID: MRR = 0.92/0.96, Mean Rank = 28.00/27.88, Hits@10 = 96.62/96.62\n",
            "DEBUG:EX-KG:FMRR valid = 0.957281, best = 0.947005\n",
            "INFO:EX-KG:[ 20] TEST: MRR = 0.93/0.97, Mean Rank = 18.82/18.64, Hits@10 = 97.83/97.83\n",
            "INFO:EX-KG:[ 21] time = 0s, violations = 69\n",
            "INFO:EX-KG:[ 22] time = 0s, violations = 62\n",
            "INFO:EX-KG:[ 23] time = 0s, violations = 54\n",
            "INFO:EX-KG:[ 24] time = 0s, violations = 59\n",
            "INFO:EX-KG:[ 25] time = 0s, violations = 49\n",
            "INFO:EX-KG:[ 26] time = 0s, violations = 53\n",
            "INFO:EX-KG:[ 27] time = 0s, violations = 58\n",
            "INFO:EX-KG:[ 28] time = 0s, violations = 42\n",
            "INFO:EX-KG:[ 29] time = 0s, violations = 58\n",
            "INFO:EX-KG:[ 30] time = 0s, violations = 60\n",
            "INFO:EX-KG:[ 30] VALID: MRR = 0.92/0.96, Mean Rank = 28.69/28.50, Hits@10 = 95.95/96.62\n",
            "DEBUG:EX-KG:FMRR valid = 0.959896, best = 0.957281\n",
            "INFO:EX-KG:[ 30] TEST: MRR = 0.93/0.98, Mean Rank = 17.74/17.55, Hits@10 = 97.55/97.83\n",
            "INFO:EX-KG:[ 31] time = 0s, violations = 59\n",
            "INFO:EX-KG:[ 32] time = 0s, violations = 45\n",
            "INFO:EX-KG:[ 33] time = 0s, violations = 54\n",
            "INFO:EX-KG:[ 34] time = 0s, violations = 51\n",
            "INFO:EX-KG:[ 35] time = 0s, violations = 40\n",
            "INFO:EX-KG:[ 36] time = 0s, violations = 46\n",
            "INFO:EX-KG:[ 37] time = 0s, violations = 54\n",
            "INFO:EX-KG:[ 38] time = 0s, violations = 47\n",
            "INFO:EX-KG:[ 39] time = 0s, violations = 52\n",
            "INFO:EX-KG:[ 40] time = 0s, violations = 44\n",
            "INFO:EX-KG:[ 40] VALID: MRR = 0.92/0.96, Mean Rank = 27.49/27.31, Hits@10 = 96.62/96.62\n",
            "DEBUG:EX-KG:FMRR valid = 0.960665, best = 0.959896\n",
            "INFO:EX-KG:[ 40] TEST: MRR = 0.93/0.97, Mean Rank = 14.08/13.90, Hits@10 = 97.83/97.83\n",
            "INFO:EX-KG:[ 41] time = 0s, violations = 34\n",
            "INFO:EX-KG:[ 42] time = 0s, violations = 49\n",
            "INFO:EX-KG:[ 43] time = 0s, violations = 42\n",
            "INFO:EX-KG:[ 44] time = 0s, violations = 56\n",
            "INFO:EX-KG:[ 45] time = 0s, violations = 36\n",
            "INFO:EX-KG:[ 46] time = 0s, violations = 29\n",
            "INFO:EX-KG:[ 47] time = 0s, violations = 46\n",
            "INFO:EX-KG:[ 48] time = 0s, violations = 22\n",
            "INFO:EX-KG:[ 49] time = 0s, violations = 34\n",
            "INFO:EX-KG:[ 50] time = 0s, violations = 33\n",
            "INFO:EX-KG:[ 50] VALID: MRR = 0.93/0.96, Mean Rank = 26.22/26.06, Hits@10 = 96.62/96.62\n",
            "DEBUG:EX-KG:FMRR valid = 0.964614, best = 0.960665\n",
            "INFO:EX-KG:[ 50] TEST: MRR = 0.93/0.98, Mean Rank = 15.11/14.87, Hits@10 = 97.55/97.83\n",
            "INFO:EX-KG:[ 50] time = 4s, violations = 33\n",
            "INFO:EX-KG:[ 50] VALID: MRR = 0.93/0.96, Mean Rank = 26.22/26.06, Hits@10 = 96.62/96.62\n",
            "DEBUG:EX-KG:FMRR valid = 0.964614, best = 0.964614\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qtd6MVfqrCF3"
      },
      "cell_type": "markdown",
      "source": [
        "The output should look similar to:\n",
        "```\n",
        "INFO:EX-KG:Fitting model HolE with trainer PairwiseStochasticTrainer and parameters Namespace(afs='sigmoid', fin='/content/holographic-embeddings/data/wn30.bin', fout='/content/wn30_holE_2e.bin', init='nunif', lr=0.1, margin=0.2, me=2, mode='rank', nb=100, ncomp=150, ne=1, no_pairwise=False, rparam=0, sampler='random-mode', test_all=10)\n",
        "INFO:EX-KG:[  1] time = 120s, violations = 773683\n",
        "INFO:EX-KG:[  2] time = 73s, violations = 334894\n",
        "INFO:EX-KG:[  2] time = 73s, violations = 334894\n",
        "INFO:EX-KG:[  2] VALID: MRR = 0.11/0.12, Mean Rank = 90012.28/90006.14, Hits@10 = 15.02/15.12\n",
        "DEBUG:EX-KG:FMRR valid = 0.122450, best = -1.000000\n",
        "INFO:EX-KG:[  2] TEST: MRR = 0.11/0.12, Mean Rank = 95344.42/95335.96, Hits@10 = 15.74/15.74\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "UoSer5UNDNBN"
      },
      "cell_type": "markdown",
      "source": [
        "# 5.0 Inspect resulting embeddings\n",
        "The output file is again a pickled serialisation of a python dictionary. It contains the `model` itself, and results for the test and validation runs as well as execution times."
      ]
    },
    {
      "metadata": {
        "id": "9aI7ct7J_skp"
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(outputs, 'rb') as fin:\n",
        "    hole_model = pickle.load(fin)\n",
        "print(type(hole_model), len(hole_model))\n",
        "for k in hole_model:\n",
        "    print(k, type(hole_model[k]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ehQ13ay2Aayi"
      },
      "cell_type": "markdown",
      "source": [
        "We are interested in the model itself, and the entity embeddings are stored in parameter `E`, which is essentially a matrix of $n_e \\times d$, where $n_e$ is the number of entities and $d$ is the dimension of each vector."
      ]
    },
    {
      "metadata": {
        "id": "EBwdXeTfAwsC"
      },
      "cell_type": "code",
      "source": [
        "model = hole_model['model']\n",
        "E = model.params['E']\n",
        "\n",
        "with open('/content/holographic-embeddings/data/data.bin', 'rb') as fin:\n",
        "  data = pickle.load(fin)\n",
        "entities = data['entities']\n",
        "embeddings=dict()\n",
        "for i,j in zip (entities,E):\n",
        "  embeddings[i]=j.tolist()\n",
        "\n",
        "import torch\n",
        "torch.save(embeddings,'embeddings.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X77zrxnRHQNP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}