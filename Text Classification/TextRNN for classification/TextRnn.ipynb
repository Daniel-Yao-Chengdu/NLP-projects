{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextRnn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4HCnPxpIwD7a",
        "yhqdlR-dwZAn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff6e3021f2324ca5834c2bbbfe91036d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd23405cbbc34afbb99849f5292b0a6a",
              "IPY_MODEL_8d0f1b113024414eaf8a2bff108fabea",
              "IPY_MODEL_423183f5115b45a8a19cbb779c8a0dcd"
            ],
            "layout": "IPY_MODEL_c984dd96b0194aea818295d436edbba9"
          }
        },
        "cd23405cbbc34afbb99849f5292b0a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3b508a8ac484fc39fe6e05168b1455c",
            "placeholder": "​",
            "style": "IPY_MODEL_7a84b591c36e40679779a3e942265fdf",
            "value": ""
          }
        },
        "8d0f1b113024414eaf8a2bff108fabea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d03ad2261e57454aaa0be153de6de2d4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2475662d499e4c24be6bbf6e0137d689",
            "value": 1
          }
        },
        "423183f5115b45a8a19cbb779c8a0dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_900f6efbf5cf49f0b33e6ba94574dd2a",
            "placeholder": "​",
            "style": "IPY_MODEL_421d9cdaa31a4a1eb3109c1b7899efb9",
            "value": " 1999995/? [03:39&lt;00:00, 11082.07it/s]"
          }
        },
        "c984dd96b0194aea818295d436edbba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3b508a8ac484fc39fe6e05168b1455c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a84b591c36e40679779a3e942265fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d03ad2261e57454aaa0be153de6de2d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2475662d499e4c24be6bbf6e0137d689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "900f6efbf5cf49f0b33e6ba94574dd2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "421d9cdaa31a4a1eb3109c1b7899efb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "* Example: [here](https://chriskhanhtran.github.io/posts/cnn-sentence-classification/)"
      ],
      "metadata": {
        "id": "p8RO5XORarYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "4HCnPxpIwD7a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M-HDdCfFwAW0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F # for use some functions like F.relu(), F.dropout()\n",
        "import string\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset preparation"
      ],
      "metadata": {
        "id": "yhqdlR-dwZAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General processing"
      ],
      "metadata": {
        "id": "1za5lgtZ0QMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For general processing of the data\n",
        "df=pd.read_json('drive/MyDrive/Colab Notebooks/All_Beauty_5.json', lines=True)\n",
        "texts = [' '.join([str(i),str(j)]) for i,j in zip(df['reviewText'],df['summary'])]\n",
        "labels = [i for i in df['overall']]\n",
        "\n",
        "new_texts=[]\n",
        "new_labels=[]\n",
        "N_5=0\n",
        "for i in range(len(labels)):\n",
        "  if labels[i]==5:\n",
        "    N_5+=1\n",
        "    if N_5<156:new_texts.append(texts[i]);new_labels.append(labels[i])\n",
        "  else: new_texts.append(texts[i]);new_labels.append(labels[i])\n",
        "texts=new_texts\n",
        "labels=new_labels\n",
        "\n",
        "#map labels to [0,1,2,3,4]\n",
        "target_names = list(set(labels))\n",
        "label2idx = {label: idx for idx, label in enumerate(target_names)}\n",
        "labels=[(label2idx[i]) for i in labels]"
      ],
      "metadata": {
        "id": "z8eeXLWywaak"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization for text\n",
        "* Use NLTK for tokenization"
      ],
      "metadata": {
        "id": "XgUvBtb_0Xje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "zZUxnfeKx8JZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64418e23-3617-4b50-9eb9-4e6357f112d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lowercase, remove punctuation, tokenization \n",
        "new_texts=[]\n",
        "for i in texts:\n",
        "  new_texts.append(' '.join(w for w in word_tokenize(i.lower()) if w not in string.punctuation))\n",
        "texts=new_texts"
      ],
      "metadata": {
        "id": "58RiyOpo1UHH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings for text"
      ],
      "metadata": {
        "id": "-mTjTqCC_Q6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our own vocab because this would make computation faster\n",
        "text_combine=' '.join(texts)\n",
        "vocab=set(text_combine.split(' '))\n",
        "vocab=list(vocab)"
      ],
      "metadata": {
        "id": "eVhS_LXmrb9m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download fasttext/word2vec pretrained embeddings\n",
        "import os\n",
        "URL = \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\"\n",
        "FILE = \"fastText\"\n",
        "\n",
        "if os.path.isdir(FILE):\n",
        "    print(\"fastText exists.\")\n",
        "else:\n",
        "    !wget -P $FILE $URL\n",
        "    !unzip $FILE/crawl-300d-2M.vec.zip -d $FILE"
      ],
      "metadata": {
        "id": "Dp-jE5NRyfmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of embeddings of our corpus\n",
        "fname=\"fastText/crawl-300d-2M.vec\"\n",
        "fin=open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "n, d = map(int, fin.readline().split())\n",
        "embedding_dic={}\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "for line in tqdm_notebook(fin):\n",
        "  tokens=line.rstrip().split(' ')\n",
        "  if tokens[0] in vocab: embedding_dic[tokens[0]]=torch.tensor(list(map(float, tokens[1:]))).unsqueeze(0)"
      ],
      "metadata": {
        "id": "ouHsYdi_sKr_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "ff6e3021f2324ca5834c2bbbfe91036d",
            "cd23405cbbc34afbb99849f5292b0a6a",
            "8d0f1b113024414eaf8a2bff108fabea",
            "423183f5115b45a8a19cbb779c8a0dcd",
            "c984dd96b0194aea818295d436edbba9",
            "e3b508a8ac484fc39fe6e05168b1455c",
            "7a84b591c36e40679779a3e942265fdf",
            "d03ad2261e57454aaa0be153de6de2d4",
            "2475662d499e4c24be6bbf6e0137d689",
            "900f6efbf5cf49f0b33e6ba94574dd2a",
            "421d9cdaa31a4a1eb3109c1b7899efb9"
          ]
        },
        "outputId": "71da06ee-7a20-446c-9447-d5a3b8b748f9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff6e3021f2324ca5834c2bbbfe91036d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the embeddings for our text\n",
        "text_embedding=[]\n",
        "for sentence in texts:\n",
        "  sentence_embedding=torch.zeros(1,300)\n",
        "  for word in sentence.split(' '):\n",
        "    if word in [*embedding_dic]: \n",
        "      sentence_embedding=torch.cat((sentence_embedding,embedding_dic[word]),0)\n",
        "  text_embedding.append(sentence_embedding[1:])"
      ],
      "metadata": {
        "id": "ewzK7WXPrPbl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the final form and divide"
      ],
      "metadata": {
        "id": "ET0NU7bl7JRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[[i, torch.tensor(j)]for i,j in zip (text_embedding,labels)]"
      ],
      "metadata": {
        "id": "VUbuCTdV67r1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# divide\n",
        "from sklearn.model_selection import train_test_split\n",
        "rest_data, test_data = train_test_split(data, test_size=0.1, random_state=1)\n",
        "train_data, val_data = train_test_split(rest_data, test_size=0.1, random_state=1)"
      ],
      "metadata": {
        "id": "2-1haeHS6-7f"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define our model and train"
      ],
      "metadata": {
        "id": "sTMu6fFx8FGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* we can use Bi-LSTM or not\n",
        "* we can concatenate the first vector and the final vector\n",
        "* we can add together the first vector and the final vector\n",
        "* we can add the vector at 1/3, 2/3, and the final vector\n",
        "* we can assign weights to different vectors\n",
        "* with all the experimentations, best accuracy on test_data+val_data is 0.871, while accuracy on training data is always 1"
      ],
      "metadata": {
        "id": "biHjAxNDqpPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextRNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_size): #set parameters of GRU and Linear\n",
        "        super().__init__()\n",
        "        self.LSTM = torch.nn.LSTM(input_size=300, hidden_size=120, batch_first=True, bidirectional=True) \n",
        "        self.linear = torch.nn.Linear(in_features=480, out_features=5)\n",
        "        self.dropout=torch.nn.Dropout(p=0.3)\n",
        "\n",
        "    def forward(self, x): #m,seq,300\n",
        "            x,(hidden_state,cell_state) = self.LSTM(x) # x：(batch_size, seq_length, 100)\n",
        "            x1=x[:,0]#m,240\n",
        "            x3=x[:,-1] #m,240\n",
        "            x=torch.cat((x1,x3),1) #m,480\n",
        "            x=self.dropout(x) #m,480\n",
        "            logits = self.linear(x)  # logits：(batch size, 5)\n",
        "            return logits\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "hidden_size=120\n",
        "model=TextRNN(hidden_size).to(device)"
      ],
      "metadata": {
        "id": "xgto75BL8GLW"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader,model,batchsize_grad,epochs,optimizer,criterion, num_batch, val_dataloader,len_val):\n",
        "    acc_steps = 100\n",
        "    model.train()\n",
        "    accumulating_batch_count = 0\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Training epoch {epoch}\")\n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "            model.train()\n",
        "            inputs=batch[0].to(device) #[m,len,300]\n",
        "            logits = model(inputs) #[m,5] \n",
        "            targets=batch[1].to(device) #m\n",
        "            loss = criterion(logits,targets)\n",
        "            loss.backward() #The gradients are computed when we call loss. backward() and are stored by PyTorch until we call optimizer.\n",
        "            if accumulating_batch_count % batchsize_grad == 0: #when accumulated batch=16, we do optimizer after 16 batches of gradients are accumulated\n",
        "                optimizer.step()\n",
        "                #scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "                model.zero_grad()\n",
        "                print (loss.item())\n",
        "            accumulating_batch_count += 1\n",
        "            # for evaluate the model after certain batches\n",
        "            if accumulating_batch_count % len(train_dataloader)==0:\n",
        "                model.eval()\n",
        "                accuracy=0\n",
        "                loss_val=0\n",
        "                for i, batch in enumerate(val_dataloader):\n",
        "                    inputs=batch[0].to(device) #[m,512]\n",
        "                    with torch.no_grad():\n",
        "                      logits = model(inputs) #[m,5]\n",
        "                      targets=batch[1].to('cpu') #m\n",
        "                      loss_val += criterion(logits,targets)\n",
        "                    softmaxed=torch.softmax(logits,-1) #[m,5]\n",
        "                    predict_label=torch.argmax(softmaxed,-1).to('cpu')\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "                    accuracy+=accuracy_score(targets,predict_label)*batch[0].shape[0]\n",
        "        #print the loss and accuracy of the validation set after each epoch\n",
        "        print (loss.item(),accuracy/len_val,loss_val.item()/len_val)\n",
        "        #save the best model\n",
        "        if accuracy/len_val>0.85: path=\"best_model.pt\"; torch.save(model.state_dict(), path) \n"
      ],
      "metadata": {
        "id": "3yjUphuXGzfa"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.load_state_dict(torch.load(path))\n",
        "batch_size=1\n",
        "epochs=20 #simple model uses more epochs\n",
        "lr=0.006 #simple models uses larger lr\n",
        "num_batch=round(len(train_data)/batch_size)-1\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(test_data+val_data, batch_size=batch_size, shuffle=True)\n",
        "len_val=len(val_dataloader)\n",
        "batchsize_grad=20\n",
        "criterion=torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "#scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * epochs)\n",
        "train(train_dataloader,model,batchsize_grad,epochs,optimizer,criterion, num_batch,val_dataloader, len_val)"
      ],
      "metadata": {
        "id": "IMC5A6xsHUC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model test"
      ],
      "metadata": {
        "id": "16OupraSCIe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#path=\"best_model.pt\" \n",
        "#model.load_state_dict(torch.load(path))\n",
        "\n",
        "val_dataloader = DataLoader(data, batch_size=1, shuffle=True)\n",
        "model.eval()\n",
        "accuracy=0\n",
        "for i, batch in enumerate(val_dataloader):\n",
        "    inputs=batch[0].to(device) #[m,512]\n",
        "    with torch.no_grad():\n",
        "      logits = model(inputs) #[m,5]\n",
        "    softmaxed=torch.softmax(logits,-1) #[m,5]\n",
        "    predict_label=torch.argmax(softmaxed,-1).to('cpu')\n",
        "    targets=batch[1].to('cpu') #m\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    accuracy+=accuracy_score(targets,predict_label)*batch[0].shape[0]\n",
        "print (accuracy/len(val_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOIdXQLgCJ-_",
        "outputId": "d85a1820-b1d0-4ba7-e2b0-37089a0c3511"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9754838709677419\n"
          ]
        }
      ]
    }
  ]
}