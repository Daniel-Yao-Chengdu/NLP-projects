{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fasttext.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reference websites\n",
        "1. Official tutorial of python, [here](https://fasttext.cc/docs/en/python-module.html#text-classification-model)\n",
        "2. Example, [here](https://towardsdatascience.com/fasttext-for-text-classification-a4b38cbff27c) "
      ],
      "metadata": {
        "id": "WRmB4Aa5Xemb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVx6RkN4FDfq"
      },
      "outputs": [],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import numpy as np, pandas as pd\n",
        "from gensim.utils import simple_preprocess"
      ],
      "metadata": {
        "id": "zqIECigMJu4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.0 Data preparation"
      ],
      "metadata": {
        "id": "EvU7yaPSTffl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In order to train and evaluate this classifier, we’ll have to prepare our data in a format fastText expects. For example:\n",
        "\n",
        "> * I really enjoyed this restaurant. Would love to visit again. _label_positive\n",
        "\n",
        "\n",
        "* We will use **[gensim’s simple_preprocess method](https://www.tutorialspoint.com/gensim/gensim_quick_guide.htm)** to tokenize our questions and remove symbols.\n",
        "\n",
        "> * lower case\n",
        "> * remove punctuation marks\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aiuO7b0bT21C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For general processing of the data\n",
        "ds = df=pd.read_json('sample_data/All_Beauty_5.json', lines=True)\n",
        "texts = [' '.join([str(i),str(j)]) for i,j in zip(df['reviewText'],df['summary'])]\n",
        "labels = [i for i in df['overall']]\n",
        "\n",
        "new_texts=[]\n",
        "new_labels=[]\n",
        "N_5=0\n",
        "for i in range(len(labels)):\n",
        "  if labels[i]==5:\n",
        "    N_5+=1\n",
        "    if N_5<156:new_texts.append(texts[i]);new_labels.append(labels[i])\n",
        "  else: new_texts.append(texts[i]);new_labels.append(labels[i])\n",
        "texts=new_texts\n",
        "labels=new_labels\n",
        "\n",
        "#for converting the dataset into fasttext-readable one\n",
        "texts=[' '.join(simple_preprocess(i)) for i in texts]\n",
        "labels=['__label__' + str(i) for i in labels]\n",
        "train_data=[i +' '+ j for i,j in zip (texts,labels)]\n",
        "\n",
        "\n",
        "#divide into train, val, test\n",
        "from sklearn.model_selection import train_test_split\n",
        "rest_data, test_data = train_test_split(train_data, test_size=0.1, random_state=1)\n",
        "train_data, val_data = train_test_split(rest_data, test_size=0.1, random_state=1)\n",
        "\n",
        "df = pd.DataFrame(train_data)\n",
        "df.to_csv('train.txt', \n",
        "          index = False, )\n",
        "          #sep = ' ',\n",
        "          #header = None, )\n",
        "\n",
        "df = pd.DataFrame(val_data)\n",
        "df.to_csv('val.txt', \n",
        "          index = False, )\n",
        "          #sep = ' ',\n",
        "          #header = None, )\n",
        "\n",
        "df = pd.DataFrame(test_data)\n",
        "df.to_csv('test.txt', \n",
        "          index = False, )\n",
        "          #sep = ' ',\n",
        "          #header = None, )"
      ],
      "metadata": {
        "id": "k7EI_DsLVYxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training"
      ],
      "metadata": {
        "id": "fS007W7V2gkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(50,120,5):\n",
        "  model = fasttext.train_supervised('train.txt', epoch=i, dim=2, wordNgrams=0)\n",
        "  if model.test('val.txt')[1] > 0.95: break"
      ],
      "metadata": {
        "id": "6GYxcRVIIvb6"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model testing"
      ],
      "metadata": {
        "id": "JcX5iscR2jIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.test('train.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pgHtH_02kun",
        "outputId": "b32b3f06-d86f-48a8-bb96-db843f547071"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(627, 0.9968102073365231, 0.9968102073365231)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other APIs"
      ],
      "metadata": {
        "id": "GRbzf7Vu1zyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model['you'] #return the vector\n",
        "model.test('val.txt')\n",
        "model.predict(val_data[3],k=2)\n",
        "model.predict([\"Which baking dish is best to bake a banana bread ?\", \"Why not put knives in the dishwasher?\"], k=3)\n",
        "model.words\n",
        "model.labels\n",
        "\n",
        "model.save_model(\"model_filename.bin\")\n",
        "model = fasttext.load_model(\"model_filename.bin\") #we can save model with smaller size with quantization, refer to the website. "
      ],
      "metadata": {
        "id": "SXY-tdtIbX-d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}