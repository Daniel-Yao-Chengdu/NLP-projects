{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert+linear for ner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reference, install and import\n"
      ],
      "metadata": {
        "id": "SBa9YZG66Q-I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vagLsUJiYXAD"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-crf\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from torchcrf import CRF\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for reading original ids and labels\n",
        "def read_original(x):\n",
        "  data = load_dataset('conll2003', split=x)\n",
        "  text=[' '.join(i) for i in data[0:-1]['tokens']]\n",
        "  id=[tokenizer(i, return_tensors=\"pt\")['input_ids'] for i in text]\n",
        "  labels=[torch.tensor(i) for i in data[0:-1]['ner_tags']]\n",
        "  return data, text, id, labels\n",
        "\n",
        "train_data,train_text,train_data_id,train_labels=read_original('train')\n",
        "val_data,val_text,val_data_id,val_labels=read_original('validation')\n",
        "test_data,test_text,test_data_id,test_labels=read_original('test')"
      ],
      "metadata": {
        "id": "Ok6MAJ3SjMSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create paddings for bert tokenizer\n",
        "def create_padding(x):\n",
        "  paddings=[]\n",
        "  for i in x:\n",
        "    sentence=i.split(' ')\n",
        "    m=[tokenizer.encode(w) for w in sentence]\n",
        "    padding=[]\n",
        "    for j in m:\n",
        "      if len(j)==3: padding.append([1])\n",
        "      else: \n",
        "        new_padding=(len(j)-2)*[0]\n",
        "        new_padding[0]=1\n",
        "        padding.append(new_padding)\n",
        "    new_padding=[]\n",
        "    for k in padding:\n",
        "      new_padding+=k\n",
        "    new_padding.insert(0,0)\n",
        "    new_padding=new_padding+[0]\n",
        "    paddings.append(new_padding)\n",
        "  return paddings\n",
        "\n",
        "train_padding=create_padding(train_text)\n",
        "val_padding=create_padding(val_text)\n",
        "test_padding=create_padding(test_text)"
      ],
      "metadata": {
        "id": "mNC2SGi0lOuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make the length of the label equal to the bert_padding by adding label -1\n",
        "#get the new labels\n",
        "def get_new_labels(labels,padding):\n",
        "  new_labels=[]\n",
        "  for j in range (len(labels)):\n",
        "    N=-1\n",
        "    new_label=[]\n",
        "    for i in padding[j]:\n",
        "      if i==0:new_label.append(-1)\n",
        "      if i!=0:N+=1; new_label.append(labels[j][N].item())\n",
        "    new_labels.append(torch.tensor(new_label))\n",
        "  return new_labels\n",
        "\n",
        "new_train_labels=get_new_labels(train_labels,train_padding)\n",
        "new_val_labels=get_new_labels(val_labels,val_padding)\n",
        "new_test_labels=get_new_labels(test_labels,test_padding)"
      ],
      "metadata": {
        "id": "EKt7WVJIm8Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up to now, the useful data is [data_id, new_labels], which have the same lengths. "
      ],
      "metadata": {
        "id": "TuAD69fGoy8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#[m,seq][m,seq]\n",
        "train_data=[[i,j.unsqueeze(0)]   for i, j   in zip(train_data_id, new_train_labels)]\n",
        "val_data  =[[i,j.unsqueeze(0)]   for i, j   in zip(val_data_id, new_val_labels)]\n",
        "test_data =[[i,j.unsqueeze(0)]   for i, j   in zip(test_data_id, new_test_labels)]"
      ],
      "metadata": {
        "id": "YNYpvudw5uLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "qQ590ytH--Nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertLinear(torch.nn.Module):\n",
        "    def __init__(self, bertmodel): \n",
        "        super().__init__()\n",
        "        self.bertmodel=bertmodel\n",
        "        self.linear=torch.nn.Linear(768,9,bias=True)\n",
        "\n",
        "    def forward(self, x): #[m,seq],[m,seq]\n",
        "        x=self.bertmodel(x)[0] #m,seq,768 \n",
        "        x=self.linear(x)#m,seq,9\n",
        "        return x\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "bertmodel=BertModel.from_pretrained('bert-base-cased').to(device)\n",
        "for param in bertmodel.parameters():\n",
        "    param.requires_grad = True\n",
        "torch.manual_seed(0)\n",
        "model=BertLinear(bertmodel).to(device)"
      ],
      "metadata": {
        "id": "4w3451hV3yUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader,model,batchsize_grad,epochs,scheduler,optimizer, num_batch, val_dataloader, len_val, criterion):\n",
        "\n",
        "    accumulating_batch_count = 0\n",
        "    for epoch in range(epochs):\n",
        "      print(f\"Training epoch {epoch+1}\")\n",
        "      model.train()\n",
        "      for i, batch in enumerate(train_dataloader):\n",
        "          x=batch[0].squeeze(1).to(device).long()#m,seq\n",
        "          logits=model(x) #m,seq,9\n",
        "          y=batch[1].squeeze(1).to(device)\n",
        "          logits=logits.view(-1,9).float()\n",
        "          y=y.view(-1).long()\n",
        "          loss=criterion(logits,y)/batchsize_grad\n",
        "          loss.backward() #The gradients are computed when we call loss. backward() and are stored by PyTorch until we call optimizer.\n",
        "\n",
        "          if accumulating_batch_count % batchsize_grad == 0: #when accumulated batch=16, we do optimizer after 16 batches of gradients are accumulated\n",
        "              optimizer.step()\n",
        "              #scheduler.step()\n",
        "              optimizer.zero_grad()\n",
        "              model.zero_grad()\n",
        "              #print (i+1,'loss',loss.item())\n",
        "          accumulating_batch_count += 1\n",
        "      \n",
        "      #eval the model\n",
        "      model.eval()\n",
        "      accuracy=0\n",
        "      total=0\n",
        "      for i, batch in enumerate(val_dataloader):\n",
        "        x=batch[0].squeeze(1).to(device).long()#m,seq\n",
        "        y=batch[1].to(device)#m,seq\n",
        "        with torch.no_grad():\n",
        "          x=model(x) #m,seq,9\n",
        "        x=torch.softmax(x,-1) #m,seq,9\n",
        "        x=torch.argmax(x,-1)#m,seq\n",
        "        preds=x.view(-1).to('cpu') #m*seq\n",
        "        y=y.view(-1).to('cpu') #m*seq\n",
        "        new_label=[]\n",
        "        new_pred=[]\n",
        "        for j in range (y.shape[-1]):\n",
        "          if y[j]!=-1:\n",
        "            new_label.append(y[j])\n",
        "            new_pred.append(preds[j])\n",
        "        #print (new_label)\n",
        "        #print (new_pred)\n",
        "        accuracy+=accuracy_score(new_label,new_pred)*len(new_pred)\n",
        "        total+=len(new_pred)\n",
        "      print ('accuracy', accuracy/total)\n",
        "      #save the best model\n",
        "      #if accuracy/len_val>0.82: path=\"best_model.pt\"; torch.save(model.state_dict(), path) "
      ],
      "metadata": {
        "id": "sjASvnOJAsCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create training data and val data\n",
        "input=train_data[0:100]\n",
        "torch.manual_seed(0)\n",
        "train_dataloader = DataLoader(input, batch_size=batch_size, shuffle=True)\n",
        "torch.manual_seed(0)\n",
        "val_dataloader = DataLoader(input, batch_size=1, shuffle=True)\n",
        "len_val=len(val_dataloader)\n",
        "\n",
        "#hyperparameter\n",
        "batch_size=1\n",
        "batchsize_grad=8\n",
        "epochs=1 #simple model uses more epochs\n",
        "lr=0.00005 #simple models uses larger lr\n",
        "num_batch=round(len(train_data)/batch_size)-1\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=epochs*(len(train_dataloader)/batchsize_grad))\n",
        "scheduler=None\n",
        "\n",
        "train(train_dataloader,model,batchsize_grad,epochs,scheduler,optimizer, num_batch,val_dataloader, len_val, criterion)"
      ],
      "metadata": {
        "id": "aoKMoYYFAsOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"drive/MyDrive/0414.pt\"\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "dMMu2WW0LsmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "py1QhbBDZgpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"drive/MyDrive/0414.pt\"\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NiJaMatTOTC",
        "outputId": "68d669dd-0814-4455-eeed-7be7f92ba813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input=test_data\n",
        "val_dataloader = DataLoader(input[0:100], batch_size=1, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "accuracy=0\n",
        "total=0\n",
        "for i, batch in enumerate(val_dataloader):\n",
        "  x=batch[0].squeeze(1).to(device).long()#m,seq\n",
        "  y=batch[1].to(device)#m,seq\n",
        "  with torch.no_grad():\n",
        "    x=model(x) #m,seq,9\n",
        "  x=torch.softmax(x,-1) #m,seq,9\n",
        "  x=torch.argmax(x,-1)#m,seq\n",
        "  preds=x.view(-1).to('cpu') #m*seq\n",
        "  y=y.view(-1).to('cpu') #m*seq\n",
        "  new_label=[]\n",
        "  new_pred=[]\n",
        "  for j in range (y.shape[-1]):\n",
        "    if y[j]!=-1:\n",
        "      new_label.append(y[j])\n",
        "      new_pred.append(preds[j])\n",
        "  #print (new_label)\n",
        "  #print (new_pred)\n",
        "  accuracy+=accuracy_score(new_label,new_pred)*len(new_pred)\n",
        "  total+=len(new_pred)\n",
        "print ('accuracy', accuracy/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CT8uLRjZfBa",
        "outputId": "465fda3c-633e-41f9-df8f-c3def2848084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.8593530239099859\n"
          ]
        }
      ]
    }
  ]
}
