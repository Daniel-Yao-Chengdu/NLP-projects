{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxZ97MQPbj90"
      },
      "source": [
        "# Fall 2022: DS-GA 1011 NLP with Representation Learning\n",
        "## Lab 4: 03-Oct-2022, Monday\n",
        "## Recurrent Neural Networks with Pytorch\n",
        "In this lab, we explore how to implement RNN based Language Model with sequential data.\n",
        "\n",
        "Examples of **sequential data**: \n",
        "\n",
        "- discrete: text\n",
        "\n",
        "- continuous: 1d audio, 2d image, 3d video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0RL_Mek0jkz"
      },
      "source": [
        "!conda install -c conda-forge jsonlines #OR\n",
        "!pip install jsonlines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl287Qi6Jucy"
      },
      "source": [
        "#Import required packages\n",
        "import os\n",
        "import jsonlines\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHRaW4wCKszD"
      },
      "source": [
        "c.f\n",
        "> [`torch.utils.data`](https://pytorch.org/docs/stable/data.html) provides PyTorch data loading utility. The key-class of this module is the `torch.utils.data.DataLoader`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhN2KkjOFSkN"
      },
      "source": [
        "---\n",
        "### Dataset\n",
        "We will use **Persona-Chat** again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxSNN-Xc-vyh"
      },
      "source": [
        "# Download data and a pretrained model\n",
        "\n",
        "# dwnld_path = './data/personachat/'\n",
        "\n",
        "### DOWNLOADING THE FILES\n",
        "### persona chat dataset\n",
        "if not os.path.exists('personachat_all_sentences_train.jsonl'):\n",
        "    !wget \"https://nyu.box.com/shared/static/q4nvswb0szelivhgyx87vd1056ttqfyi.jsonl\" -O 'personachat_all_sentences_train.jsonl'\n",
        "if not os.path.exists('personachat_all_sentences_valid.jsonl'):\n",
        "    !wget \"https://nyu.box.com/shared/static/8krcizo8sms1m0ppy7uiwfcx4a3l5nsq.jsonl\" -O 'personachat_all_sentences_valid.jsonl'\n",
        "if not os.path.exists('personachat_all_sentences_test.jsonl'):\n",
        "    !wget \"https://nyu.box.com/shared/static/im7we9k2gcf8kslqnfamsimicgosuw9y.jsonl\" -O 'personachat_all_sentences_test.jsonl'\n",
        "\n",
        "### pretrained rnn model\n",
        "if not os.path.exists('personachat_rnn_lm.pt'):\n",
        "    !wget \"https://nyu.box.com/shared/static/3jl9erctnvbefnczgmetkdil0xwpcxzb.pt\" -O 'personachat_rnn_lm.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMLDPoL23cnI"
      },
      "source": [
        "# For Windows users\n",
        "# !pip install wget\n",
        "# import wget\n",
        "\n",
        "# # Download data and a pretrained model\n",
        "\n",
        "# ### DOWNLOADING THE FILES\n",
        "# ### persona chat dataset\n",
        "# if not os.path.exists('personachat_all_sentences_train.jsonl'):\n",
        "#     wget.download(\"https://nyu.box.com/shared/static/q4nvswb0szelivhgyx87vd1056ttqfyi.jsonl\",'personachat_all_sentences_train.jsonl')\n",
        "# if not os.path.exists('personachat_all_sentences_valid.jsonl'):\n",
        "#     wget.download(\"https://nyu.box.com/shared/static/8krcizo8sms1m0ppy7uiwfcx4a3l5nsq.jsonl\",'personachat_all_sentences_valid.jsonl')\n",
        "# if not os.path.exists('personachat_all_sentences_test.jsonl'):\n",
        "#     wget.download(\"https://nyu.box.com/shared/static/im7we9k2gcf8kslqnfamsimicgosuw9y.jsonl\",'personachat_all_sentences_test.jsonl')\n",
        "\n",
        "# ## wikitext-2 dataset\n",
        "# if not os.path.exists('wikitext2-sentencized.json'):\n",
        "#     wget.download(\"https://nyu.box.com/shared/static/9kb7l7ci30hb6uahhbssjlq0kctr5ii4.json\",'wikitext2-sentencized.json')\n",
        "\n",
        "# ### pretrained rnn model\n",
        "# if not os.path.exists('personachat_rnn_lm.pt'):\n",
        "#     wget.download(\"https://nyu.box.com/shared/static/3jl9erctnvbefnczgmetkdil0xwpcxzb.pt\",'personachat_rnn_lm.pt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLWS5Wa7HmbQ"
      },
      "source": [
        "#### Preparing data: dictionary and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHNMLD9a-v8E"
      },
      "source": [
        "def load_personachat(basedir):\n",
        "    datasets_fnames = {\n",
        "        'train': os.path.join(basedir, 'personachat_all_sentences_train.jsonl'), #jsonl file is different from json. Each line in jsonl file is an object. \n",
        "        'valid': os.path.join(basedir, 'personachat_all_sentences_valid.jsonl'),\n",
        "        'test': os.path.join(basedir, 'personachat_all_sentences_test.jsonl'),\n",
        "    }\n",
        "    \n",
        "    datasets_text = {\n",
        "        'train': [],\n",
        "        'valid': [],\n",
        "        'test': [],\n",
        "    }\n",
        "    \n",
        "    for split, fname in datasets_fnames.items():\n",
        "        for token_dict in jsonlines.open(fname):\n",
        "            datasets_text[split].append(token_dict['tokens'])\n",
        "    \n",
        "    return datasets_text\n",
        "\n",
        "class Dictionary(object): #maps words to indices\n",
        "    def __init__(self, datasets, include_valid=False):\n",
        "        self.tokens = []\n",
        "        self.ids = {}\n",
        "        self.counts = {}\n",
        "        \n",
        "        # add special tokens\n",
        "        self.add_token('<bos>') #beginning of sentence\n",
        "        self.add_token('<eos>') #end of sentence\n",
        "        self.add_token('<pad>')\n",
        "        self.add_token('<unk>') #unknown. Needed in case use with text with word that isn't in vocab\n",
        "        \n",
        "        for line in tqdm(datasets['train']):\n",
        "            for w in line:\n",
        "                self.add_token(w)\n",
        "                    \n",
        "        if include_valid is True:\n",
        "            for line in tqdm(datasets['valid']):\n",
        "                for w in line:\n",
        "                    self.add_token(w)\n",
        "                            \n",
        "    def add_token(self, w):\n",
        "        if w not in self.tokens:\n",
        "            self.tokens.append(w)\n",
        "            _w_id = len(self.tokens) - 1\n",
        "            self.ids[w] = _w_id\n",
        "            self.counts[w] = 1\n",
        "        else:\n",
        "            self.counts[w] += 1\n",
        "\n",
        "    def get_id(self, w):\n",
        "        return self.ids[w]\n",
        "    \n",
        "    def get_token(self, idx):\n",
        "        return self.tokens[idx]\n",
        "    \n",
        "    def decode_idx_seq(self, l):\n",
        "        return [self.tokens[i] for i in l]\n",
        "    \n",
        "    def encode_token_seq(self, l):\n",
        "        return [self.ids[i] if i in self.ids else self.ids['<unk>'] for i in l]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.tokens)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUYTjIOQ-wDH"
      },
      "source": [
        "personachat_dataset = load_personachat('./')\n",
        "persona_dict = Dictionary(personachat_dataset, include_valid=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO9Ao6uK9fqM"
      },
      "source": [
        "print(len(persona_dict))\n",
        "for i in range(10):\n",
        "    print(i, persona_dict.get_token(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb9Va-p4bj96"
      },
      "source": [
        "---\n",
        "### Model: Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR-3DRYL9fqX"
      },
      "source": [
        "#### RNN as a sequence processing tool\n",
        "\n",
        "Consider a sequential input $\\mathbf{x}_1^T = (x_1, x_2, \\cdots, x_T)$.\n",
        "\n",
        "Now our goal is to estimate the probability distribution $p(x_t|x_{<t})$, i.e. the history is full prefix of the input before the token $x_t$. Obviosuly, in this case every token's history depends on the particular input and token position.\n",
        "\n",
        "Recurrent neural network can be seen as a function $h_t = f(x_t, h_{t-1}; \\theta)$, where $h_t$ is an internal (hidden) state of the model at time step $t$, and $x_t$ is an input signal at time step $t$.\n",
        "\n",
        "How exactly is $f$ defined? It depends on a particular architecture. There are plenty of them such as Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU) etc.\n",
        "\n",
        "Consider the simplest possible case: $$h_t = f(x_t, h_{t-1}; \\theta) = \\text{tanh}(a_t)\\\\ a_t = b + W \\cdot h_{t-1} + U \\cdot x_t$$ Adding previous hidden state\n",
        "\n",
        "Lets assume that size of the hidden state $|h_t| = 32$. ***Then what is the dimensionality of $W$?*** $dim(o)\\times dim(h)$\n",
        "\n",
        "What about $x_t$? In count based LM each token is represented by a single number? Here we use the distributional representation of the token.\n",
        "\n",
        "Lets assume size of the token embedding here $|x_t| = 300$. ***Then what is the dimensionality of $U$?***\n",
        "\n",
        "***Then what is the dimensionality of $b$?***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLTwdNF-bj97"
      },
      "source": [
        "#### RNNCell\n",
        "\n",
        "*RNNCell* is a building block of the RNN model. Pytorch RNN model allows to create multi-layer network, i.e. it creates a separate RNNCell for every layer and is able to process the whole sequences of data by iteratively applying RNNCell step by step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1WfgVLybj98"
      },
      "source": [
        "from torch.nn import RNNCell \n",
        "\n",
        "#  always try to read the documentation \n",
        "RNNCell?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EinnRCTybj9-"
      },
      "source": [
        "***Why there are two bias terms in Elman RNNCell? Is this equivalent to a single bias term as we wrote? Why?***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OseW45d9bj9_",
        "outputId": "8300c5be-6e85-473a-a647-df9df67f5573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# quick test\n",
        "hidden_size = 32\n",
        "embed_size = 300\n",
        "\n",
        "rnn_cell = RNNCell(embed_size, hidden_size)\n",
        "rnn_cell"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNCell(300, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnPEPW5Nbj-B",
        "outputId": "c263e675-56b6-4afa-bf3b-4edd73271430",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "random_hidden = torch.rand(1, hidden_size)\n",
        "print(random_hidden.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TIjbLsMbj-C",
        "outputId": "d8117d37-6986-4785-e270-12ca1dcc75d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "random_input = torch.rand(1, embed_size)\n",
        "print(random_input.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n2k_CEBbj-E",
        "outputId": "e929a0ef-5112-46f7-8284-548609bb548a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "new_hidden = rnn_cell(random_input, random_hidden)\n",
        "print(new_hidden.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones_like(random_input)"
      ],
      "metadata": {
        "id": "O2iVA5H4sU6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyAi2Otsbj-G"
      },
      "source": [
        "***What is the first 1 in the size tuple?*** -> *Batch size*. \n",
        "\n",
        "#### Batch size\n",
        "\n",
        "\n",
        "*Batch size* is the number of elements that *mini batch* contains. Do not confuse the batch size and time/sequence axis.\n",
        "\n",
        "Why do we need a *batch size*? To save computation time. Matrix multiplications give us this speed-up at very low cast thanks to efficient implementations.\n",
        "\n",
        "Consider the following input batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2P6hWF3bj-H",
        "outputId": "9fb75573-04f9-44be-8907-ce39fb776f9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "example_2 = [ 'hello this is the first sample in mini batch', 'and this is the second sample in mini batch' ]\n",
        "example_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello this is the first sample in mini batch',\n",
              " 'and this is the second sample in mini batch']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYmRMMbGbj-J"
      },
      "source": [
        "This *mini batch* contains two independent sentences, i.e. the batch size is 2. \n",
        "\n",
        "The actual length of each sample is 9. We are lucky that they have the same length, but what to do if not? For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVZN9JRWbj-J",
        "outputId": "4f9a87eb-e533-4cc2-9303-031ad772b1fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "example_3 = ['this sample is quite long here since we want to address this case', 'this one is short']\n",
        "example_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this sample is quite long here since we want to address this case',\n",
              " 'this one is short']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvsW4dnlbj-L"
      },
      "source": [
        "As a workaround we introduce the special padding token `<pad>`, then `example_3` will looks as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VN-2qJ7bj-M",
        "outputId": "5241e9a7-1ecc-459c-b3cf-8b0347c697a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# toy function\n",
        "\n",
        "def pad_strings(minibatch):\n",
        "    max_len_sample = max(len(i.split(' ')) for i in minibatch)\n",
        "\n",
        "    result = []\n",
        "    for line in minibatch:\n",
        "        line_len = len(line.split(' '))\n",
        "        padding_str = ' ' + '<pad> '*(max_len_sample-line_len)\n",
        "        result.append(line+padding_str)\n",
        "        \n",
        "    return result\n",
        "\n",
        "pad_strings(example_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this sample is quite long here since we want to address this case ',\n",
              " 'this one is short <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4QaNlS2bj-O"
      },
      "source": [
        "Now at time step $t=4$ input to RNNCell is `[['long'], ['<pad>']]`.\n",
        "\n",
        "#### RNN\n",
        "*RNN* is sequence of *RNN cell*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCvackw4bj-O"
      },
      "source": [
        "from torch.nn import RNNBase, RNN\n",
        "\n",
        "RNNBase.__init__??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_qmYXYMbj-Q",
        "outputId": "32ff58ae-97bf-4133-bcfd-f8a3886da497"
      },
      "source": [
        "RNNBase.forward?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[0;31mSignature:\u001b[0m\n",
              "\u001b[0mRNNBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m    \u001b[0mhx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
              "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
              "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
              "\u001b[0;31mFile:\u001b[0m      /opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\n",
              "\u001b[0;31mType:\u001b[0m      function\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlUBUtnhbj-f"
      },
      "source": [
        "#### Embedding layer\n",
        "\n",
        "*Embedding layer* serves as a differentiable look-up table. Given the token id, it returns corresponding vector which represents the given word.\n",
        "\n",
        "Pytorch provides this functionality for us with `torch.nn.Embedding`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7wBvXaYbj-g"
      },
      "source": [
        "from torch.nn import Embedding\n",
        "\n",
        "Embedding?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPUY40tXbj-m",
        "outputId": "844b1f83-4511-4fc6-e965-efa9498c28e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Example embedding layer\n",
        "\n",
        "lookup = Embedding(num_embeddings=len(persona_dict), embedding_dim=256, padding_idx=persona_dict.get_id('<pad>')) #you don't want to change embedding padding since there's no info there\n",
        "lookup"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(20089, 256, padding_idx=2)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSDJy98Jbj-o",
        "outputId": "67280c9a-48a5-46c7-f561-897e68aa5868",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lookup.weight.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20089, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WMCuASKbj-s",
        "outputId": "02ec95be-6d70-4b5a-a355-de318be43e29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Example input\n",
        "\n",
        "input_ = persona_dict.encode_token_seq('hello world'.split(' '))\n",
        "print(f'discrete input: {[input_]}')\n",
        "\n",
        "input_continuous = lookup(torch.tensor([input_], dtype=torch.long))\n",
        "print(f'continuous input size: {input_continuous.size()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "discrete input: [[179, 373]]\n",
            "continuous input size: torch.Size([1, 2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyXi2nkDbj-t"
      },
      "source": [
        "#### Creating the RNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0OIKqYlbj-u"
      },
      "source": [
        "input_size = lookup.weight.size(1)\n",
        "vocab_size = lookup.weight.size(0)\n",
        "hidden_size = 1024\n",
        "num_layers = 1\n",
        "\n",
        "rnn_lm = RNN(input_size, hidden_size, num_layers, batch_first=True) #batchfirst is important - tells you dimension that minibatch is on. Will give model if have it backward but will be wrong. We create batch in loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0d5Brchbj-w",
        "outputId": "03d28be0-55f7-4ed2-dcca-ada14f37d526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rnn_lm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(256, 1024, batch_first=True)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMYxMNsLbj-y"
      },
      "source": [
        "from torch.nn import Linear\n",
        "# linear projection layer is needed to convert the hidden representation into the token-level output probability distribution\n",
        "\n",
        "projection = Linear(hidden_size, vocab_size, bias=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxtW_Rxnbj-0",
        "outputId": "a5c30336-d602-482f-e31a-098da033d4f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "projection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1024, out_features=20089, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLLD95Z2G3my"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zev2mdGbj--"
      },
      "source": [
        "### Customize our model\n",
        "\n",
        "Now we know how to define each part of LM. Next we are going to make an abstract LM module with all previously discussed parts, as well as data loader which pads and make batches out of our training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwPXurN1bj_F"
      },
      "source": [
        "#### Dataset\n",
        "Making an efficient dataset using `torch.utils.data.DataLoader`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8TCegGeOZy7"
      },
      "source": [
        "cf. \n",
        "> [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) combines a dataset and a sampler, and provides an iterable over the given dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9inTW9TO-v-l"
      },
      "source": [
        "def tokenize_dataset(datasets, dictionary, ngram_order=2): #substitute words with numbers. Sometimes can include splitting strings, dealing with punctuation and symbols.\n",
        "    tokenized_datasets = {}\n",
        "    for split, dataset in datasets.items():\n",
        "        _current_dictified = []\n",
        "        for l in tqdm(dataset):\n",
        "            l = ['<bos>']*(ngram_order-1) + l + ['<eos>']\n",
        "            encoded_l = dictionary.encode_token_seq(l)\n",
        "            _current_dictified.append(encoded_l)\n",
        "        tokenized_datasets[split] = _current_dictified\n",
        "        \n",
        "    return tokenized_datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8owF_WQMbj_H"
      },
      "source": [
        "class TensoredDataset(Dataset):\n",
        "    def __init__(self, list_of_lists_of_tokens):\n",
        "        self.input_tensors = []\n",
        "        self.target_tensors = []\n",
        "        \n",
        "        for sample in list_of_lists_of_tokens:\n",
        "            self.input_tensors.append(torch.tensor([sample[:-1]], dtype=torch.long))\n",
        "            self.target_tensors.append(torch.tensor([sample[1:]], dtype=torch.long))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.input_tensors)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # return a (input, target) tuple\n",
        "        return (self.input_tensors[idx], self.target_tensors[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN-To_JLS9gH",
        "outputId": "acdf9e0c-e020-47de-faf1-56c2bc78bc05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "personachat_tokenized_datasets = tokenize_dataset(personachat_dataset, persona_dict)\n",
        "persona_tensor_dataset = {}\n",
        "\n",
        "for split, listoflists in personachat_tokenized_datasets.items():\n",
        "    persona_tensor_dataset[split] = TensoredDataset(listoflists)\n",
        "    \n",
        "# check the first example\n",
        "persona_tensor_dataset['train'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 133176/133176 [00:00<00:00, 217817.02it/s]\n",
            "100%|██████████| 16181/16181 [00:00<00:00, 253146.36it/s]\n",
            "100%|██████████| 15608/15608 [00:00<00:00, 86635.11it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  4,  5,  6,  7,  8,  9, 10, 11, 12]]),\n",
              " tensor([[ 4,  5,  6,  7,  8,  9, 10, 11, 12,  1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO9bQBklOE0g"
      },
      "source": [
        "torch.utils.data.DataLoader?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZYTS4jc0lyW",
        "outputId": "10b584e6-c2a1-4660-eb09-a98e36623e67"
      },
      "source": [
        "torch.cat?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[0;31mDocstring:\u001b[0m\n",
              "cat(tensors, dim=0, out=None) -> Tensor\n",
              "\n",
              "Concatenates the given sequence of :attr:`seq` tensors in the given dimension.\n",
              "All tensors must either have the same shape (except in the concatenating\n",
              "dimension) or be empty.\n",
              "\n",
              ":func:`torch.cat` can be seen as an inverse operation for :func:`torch.split`\n",
              "and :func:`torch.chunk`.\n",
              "\n",
              ":func:`torch.cat` can be best understood via examples.\n",
              "\n",
              "Args:\n",
              "    tensors (sequence of Tensors): any python sequence of tensors of the same type.\n",
              "        Non-empty tensors provided must have the same shape, except in the\n",
              "        cat dimension.\n",
              "    dim (int, optional): the dimension over which the tensors are concatenated\n",
              "    out (Tensor, optional): the output tensor.\n",
              "\n",
              "Example::\n",
              "\n",
              "    >>> x = torch.randn(2, 3)\n",
              "    >>> x\n",
              "    tensor([[ 0.6580, -1.0969, -0.4614],\n",
              "            [-0.1034, -0.5790,  0.1497]])\n",
              "    >>> torch.cat((x, x, x), 0)\n",
              "    tensor([[ 0.6580, -1.0969, -0.4614],\n",
              "            [-0.1034, -0.5790,  0.1497],\n",
              "            [ 0.6580, -1.0969, -0.4614],\n",
              "            [-0.1034, -0.5790,  0.1497],\n",
              "            [ 0.6580, -1.0969, -0.4614],\n",
              "            [-0.1034, -0.5790,  0.1497]])\n",
              "    >>> torch.cat((x, x, x), 1)\n",
              "    tensor([[ 0.6580, -1.0969, -0.4614,  0.6580, -1.0969, -0.4614,  0.6580,\n",
              "             -1.0969, -0.4614],\n",
              "            [-0.1034, -0.5790,  0.1497, -0.1034, -0.5790,  0.1497, -0.1034,\n",
              "             -0.5790,  0.1497]])\n",
              "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76j3yHD7bj_K"
      },
      "source": [
        "def pad_list_of_tensors(list_of_tensors, pad_token):\n",
        "    max_length = max([t.size(-1) for t in list_of_tensors])\n",
        "    padded_list = []\n",
        "    \n",
        "    for t in list_of_tensors:\n",
        "        padded_tensor = torch.cat([t, torch.tensor([[pad_token]*(max_length - t.size(-1))], dtype=torch.long)], dim = -1)\n",
        "        padded_list.append(padded_tensor)\n",
        "        \n",
        "    padded_tensor = torch.cat(padded_list, dim=0)\n",
        "    \n",
        "    return padded_tensor\n",
        "\n",
        "def pad_collate_fn(batch):\n",
        "    # batch is a list of sample tuples\n",
        "    input_list = [s[0] for s in batch]\n",
        "    target_list = [s[1] for s in batch]\n",
        "    \n",
        "    pad_token = persona_dict.get_id('<pad>')\n",
        "    #pad_token = 2\n",
        "    \n",
        "    input_tensor = pad_list_of_tensors(input_list, pad_token)\n",
        "    target_tensor = pad_list_of_tensors(target_list, pad_token)\n",
        "    \n",
        "    return input_tensor, target_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwBqO3z7bj_L"
      },
      "source": [
        "persona_loaders = {}\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "for split, persona_dataset in persona_tensor_dataset.items():\n",
        "    persona_loaders[split] = DataLoader(persona_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHqYjtCYbj--"
      },
      "source": [
        "#### Model\n",
        "Making our own `nn.Module` model to combine Embedding, RNN and Projection in a single object\n",
        "\n",
        "Above we have created each part of the language model separately. Further we made a criterion and optimizer which takes every parameter we are going to update with an optimizer. To simplify the whole process now we create an abstract model class which combines all parts in a single RNNLanguageModel object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdlUbyiybj_A"
      },
      "source": [
        "class RNNLanguageModel(nn.Module): #RNN is only difference from previous model\n",
        "    \"\"\"\n",
        "    This model combines embedding, rnn and projection layer into a single model\n",
        "    \"\"\"\n",
        "    def __init__(self, options):\n",
        "        super().__init__()\n",
        "        \n",
        "        # create each LM part here \n",
        "        self.lookup = nn.Embedding(num_embeddings=options['num_embeddings'], embedding_dim=options['embedding_dim'], padding_idx=options['padding_idx'])\n",
        "        self.rnn = nn.RNN(options['input_size'], options['hidden_size'], options['num_layers'], dropout=options['rnn_dropout'], batch_first=True)\n",
        "        self.projection = nn.Linear(options['hidden_size'], options['num_embeddings'])\n",
        "        \n",
        "    def forward(self, encoded_input_sequence):\n",
        "        \"\"\"\n",
        "        Forward method process the input from token ids to logits\n",
        "        \"\"\"\n",
        "        embeddings = self.lookup(encoded_input_sequence)\n",
        "        rnn_outputs = self.rnn(embeddings)\n",
        "        logits = self.projection(rnn_outputs[0]) #convenient for seq to seq models. check shape of output. lstm gives different\n",
        "        \n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn.Linear(options['hidden_size','you'],2)"
      ],
      "metadata": {
        "id": "TbVSqE2AwSjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQB-RbIhbj_B"
      },
      "source": [
        "# Create a model if we do not want to use pretrained model\n",
        "\n",
        "load_pretrained = True\n",
        "\n",
        "num_gpus = torch.cuda.device_count()\n",
        "if num_gpus > 0:\n",
        "    current_device = 'cuda'\n",
        "else:\n",
        "    current_device = 'cpu'\n",
        "\n",
        "if load_pretrained:\n",
        "    if not os.path.exists('personachat_rnn_lm.pt'):\n",
        "        raise EOFError('Download pretrained model!')\n",
        "    model_dict = torch.load('personachat_rnn_lm.pt', map_location=current_device)\n",
        "    \n",
        "    options = model_dict['options']\n",
        "    model = RNNLanguageModel(options).to(current_device)\n",
        "    model.load_state_dict(model_dict['model_dict'])\n",
        "    \n",
        "else:\n",
        "    embedding_size = 256\n",
        "    hidden_size = 512\n",
        "    num_layers = 3\n",
        "    rnn_dropout = 0.3\n",
        "\n",
        "    options = {\n",
        "        'num_embeddings': len(persona_dict),\n",
        "        'embedding_dim': embedding_size,\n",
        "        'padding_idx': persona_dict.get_id('<pad>'),\n",
        "        'input_size': embedding_size,\n",
        "        'hidden_size': hidden_size,\n",
        "        'num_layers': num_layers,\n",
        "        'rnn_dropout': rnn_dropout,\n",
        "    }\n",
        "\n",
        "    \n",
        "\n",
        "    model = RNNLanguageModel(options).to(current_device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=persona_dict.get_id('<pad>'))\n",
        "\n",
        "model_parameters = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = optim.SGD(model_parameters, lr=0.001, momentum=0.999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmMLIrhjbj_D",
        "outputId": "e30d50c9-4547-4c4e-86d3-75f45c9eab4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLanguageModel(\n",
              "  (lookup): Embedding(20089, 256, padding_idx=2)\n",
              "  (rnn): RNN(256, 512, num_layers=3, batch_first=True, dropout=0.3)\n",
              "  (projection): Linear(in_features=512, out_features=20089, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4WayxKfV3Ua",
        "outputId": "26fbb17c-c5c0-48fa-c546-fd5ff5878d34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_dict.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['options', 'loss_cache', 'model_dict'])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVDzkw0dWaCm",
        "outputId": "225bf2ce-5e60-4829-f5fa-1d2329ba9128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_dict['options']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_embeddings': 20089,\n",
              " 'embedding_dim': 256,\n",
              " 'padding_idx': 2,\n",
              " 'input_size': 256,\n",
              " 'hidden_size': 512,\n",
              " 'num_layers': 3,\n",
              " 'rnn_dropout': 0.3}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6nknrolRIfy"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw28_6qXbj_M",
        "outputId": "de393665-5fc1-4336-e1bd-dea5a2c7473b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "plot_cache = []\n",
        "\n",
        "for epoch_number in range(100):\n",
        "    avg_loss=0\n",
        "    if not load_pretrained:\n",
        "        # do train\n",
        "        model.train()\n",
        "        train_log_cache = []\n",
        "        for i, (inp, target) in enumerate(persona_loaders['train']):\n",
        "            optimizer.zero_grad()\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            logits = model(inp)\n",
        "            \n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_log_cach.eappend(loss.item())\n",
        "            \n",
        "            if i % 100 == 0:\n",
        "                avg_loss = sum(train_log_cache)/len(train_log_cache)\n",
        "                print('Step {} avg train loss = {:.{prec}f}'.format(i, avg_loss, prec=4))\n",
        "                train_log_cache = []\n",
        "            \n",
        "    #do valid\n",
        "    valid_losses = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (inp, target) in enumerate(persona_loaders['valid']):\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            logits = model(inp)\n",
        "\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), target.view(-1))\n",
        "            valid_losses.append(loss.item())\n",
        "        avg_val_loss = sum(valid_losses) / len(valid_losses)\n",
        "        print('Validation loss after {} epoch = {:.{prec}f}'.format(epoch_number, avg_val_loss, prec=4))\n",
        "        \n",
        "    plot_cache.append((avg_loss, avg_val_loss))\n",
        "\n",
        "    if load_pretrained:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss after 0 epoch = 3.6498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTyb2zZYbj_O"
      },
      "source": [
        "---\n",
        "### Evaluation: Perplexity\n",
        "#### Recap: Perplexity and how to get it right\n",
        "\n",
        "Intuitively, a good model should assign high probabilities to sequences from the 'true' distribution that it is modeling.\n",
        "\n",
        "A common way of quantifying this is with **perplexity**, a metric inversely-proportional to the probability that the model assigns to a set of sequences, e.g. a 'test set':\n",
        "\n",
        "\\begin{align}\n",
        "\\huge \\text{ppl}(p, D) &\\huge = -\\frac{1}{N_{total}}\\log p(D)\n",
        "\\end{align}\n",
        "\n",
        "where $D=\\{(w_1,\\ldots,w_{N_i})_i\\}_{i=1}^M$ is a dataset of $M$ sequences with total length $N_{\\text{total}}=\\sum_{i}N_i$.\n",
        "\n",
        "Intuitively, when measured in exponential form ($2^{-\\frac{1}{N_{total}}\\log_2 p(D)}$), **_perplexity measures the average rank of the true next-token, when tokens are ordered by the model's conditional probabilities_**. It is defined on $[1,\\infty)$, with 1 being a perfect model (assigning probability 1 to $D$), and a 'worse' model as perplexity increases. Section 1.3 of [[Chen & Goodman 1998]](https://dash.harvard.edu/bitstream/handle/1/25104739/tr-10-98.pdf?sequence=1) has a concise summary of perplexity and its motivation.\n",
        "\n",
        "### Perplexity in our case\n",
        "\n",
        "In our case model computes the loss for every token in the output sequence. There are several important points:\n",
        "\n",
        "- we have to mask loss assigned to padding token. \\<pad\\> is introduced in order to shape batches of specific size and such tokens do not contribute to the actual data. To our luck, pytorch already handles this in the criterion (check that **ignore_index=**argument)\n",
        "- we have to check the base of the logaithm: by default **torch.log** uses natural base $e$, in order to convert that to base 2 we do the following math: log_2 p = log_e p / log_e 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAV_hzMvbj_O"
      },
      "source": [
        "if load_pretrained:\n",
        "    plot_cache = model_dict['loss_cache']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhTtmqBfufyE",
        "outputId": "dc6bfc9a-a452-4858-8c63-5d20328bd963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "epochs = numpy.array(list(range(len(plot_cache))))\n",
        "plt.plot(epochs, [i[0] for i in plot_cache], label='Train loss')\n",
        "plt.plot(epochs, [i[1] for i in plot_cache], label='Valid loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('Loss curves')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_A4w1QFufyN",
        "outputId": "d924244a-c80c-4151-b7e4-2a61bb5671fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "epochs = numpy.array(list(range(len(plot_cache))))\n",
        "plt.plot(epochs, [2**(i[0]/numpy.log(2)) for i in plot_cache], label='Train ppl')\n",
        "plt.plot(epochs, [2**(i[1]/numpy.log(2)) for i in plot_cache], label='Valid ppl')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('PPL curves')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAvP_FXgbj_W"
      },
      "source": [
        "### Compare the results\n",
        "#### Checking some trigram probabilities\n",
        "\n",
        "In the previous lab we have this using 3gram count based LM:\n",
        "\n",
        "$p( \\text{dog }| \\text{ my pet} ) = 0.03030$\n",
        "\n",
        "$p( \\text{zebra } | \\text{ my pet} ) = 0.01515$\n",
        "\n",
        "$p( \\text{lion } | \\text{ my pet} ) = 0$\n",
        "\n",
        "The last trigram had $p=0$ since such trigram did not appear in the training corpus.\n",
        "\n",
        "Lets check what we get using personachat dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMG0r9zwbj_X",
        "outputId": "5d42e386-8f29-47e9-f089-e7c9fa182dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "def get_prob_of_token_given_prefix(prefix, token):\n",
        "    inp = persona_dict.encode_token_seq(prefix.split(' '))\n",
        "    #print(inp)\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        logits = model(torch.tensor([inp], dtype=torch.long).to(current_device))\n",
        "        \n",
        "    tokid = persona_dict.get_id(token)\n",
        "    prob_distr = torch.softmax(logits[0,-1], dim=-1)\n",
        "    return prob_distr[tokid]\n",
        "\n",
        "prefix='my pet'\n",
        "\n",
        "for w in ['dog', 'zebra', 'lion', 'hotdog', 'table', 'math', 'pizza']:\n",
        "    prob = get_prob_of_token_given_prefix(prefix, w)\n",
        "    print('p( {} | {} ) = {:.{prec}f}'.format(w, prefix, prob, prec=8))\n",
        "    \n",
        "print('====================')\n",
        "\n",
        "prefix='<bos> i have a'\n",
        "\n",
        "for w in ['dog', 'zebra', 'lion', 'hotdog', 'table', 'math', 'pizza']:\n",
        "    prob = get_prob_of_token_given_prefix(prefix, w)\n",
        "    print('p( {} | {} ) = {:.{prec}f}'.format(w, prefix, prob, prec=8))\n",
        "    \n",
        "print('====================')\n",
        "\n",
        "prefix='i have'\n",
        "\n",
        "for w in ['dog', 'zebra', 'lion', 'hotdog', 'table', 'math', 'pizza']:\n",
        "    prob = get_prob_of_token_given_prefix(prefix, w)\n",
        "    print('p( {} | {} ) = {:.{prec}f}'.format(w, prefix, prob, prec=8))\n",
        "\n",
        "print('====================')\n",
        "\n",
        "prefix='have'\n",
        "\n",
        "for w in ['dog', 'zebra', 'lion', 'hotdog', 'table', 'math', 'pizza']:\n",
        "    prob = get_prob_of_token_given_prefix(prefix, w)\n",
        "    print('p( {} | {} ) = {:.{prec}f}'.format(w, prefix, prob, prec=8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p( dog | my pet ) = 0.00360091\n",
            "p( zebra | my pet ) = 0.00063178\n",
            "p( lion | my pet ) = 0.00004970\n",
            "p( hotdog | my pet ) = 0.00002596\n",
            "p( table | my pet ) = 0.00002861\n",
            "p( math | my pet ) = 0.00003056\n",
            "p( pizza | my pet ) = 0.00003829\n",
            "====================\n",
            "p( dog | <bos> i have a ) = 0.06960335\n",
            "p( zebra | <bos> i have a ) = 0.00016325\n",
            "p( lion | <bos> i have a ) = 0.00032840\n",
            "p( hotdog | <bos> i have a ) = 0.00002465\n",
            "p( table | <bos> i have a ) = 0.00001450\n",
            "p( math | <bos> i have a ) = 0.00002590\n",
            "p( pizza | <bos> i have a ) = 0.00027605\n",
            "====================\n",
            "p( dog | i have ) = 0.00005810\n",
            "p( zebra | i have ) = 0.00000022\n",
            "p( lion | i have ) = 0.00000022\n",
            "p( hotdog | i have ) = 0.00000029\n",
            "p( table | i have ) = 0.00000070\n",
            "p( math | i have ) = 0.00000164\n",
            "p( pizza | i have ) = 0.00003808\n",
            "====================\n",
            "p( dog | have ) = 0.00000301\n",
            "p( zebra | have ) = 0.00000043\n",
            "p( lion | have ) = 0.00000049\n",
            "p( hotdog | have ) = 0.00000143\n",
            "p( table | have ) = 0.00000090\n",
            "p( math | have ) = 0.00000037\n",
            "p( pizza | have ) = 0.00000082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4zVv--owi3d",
        "outputId": "0460d9b0-5501-44d0-9be6-0f6459af8c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "def get_top_token_given_prefix(prefix):\n",
        "    inp = persona_dict.encode_token_seq(prefix.split(' '))\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        logits = model(torch.tensor([inp], dtype=torch.long).to(current_device))\n",
        "        \n",
        "    prob_distr = torch.softmax(logits[0,-1], dim=-1)\n",
        "    sorted_best_probs, sorted_best_toks = torch.topk(prob_distr, 20)\n",
        "\n",
        "    for i in range(sorted_best_toks.size(0)):\n",
        "        print('p( {} | {} ) = {:.{prec}f}'.format(persona_dict.decode_idx_seq([sorted_best_toks[i]])[0], prefix, sorted_best_probs[i], prec=8))\n",
        "\n",
        "    print(persona_dict.decode_idx_seq(sorted_best_toks))\n",
        "\n",
        "get_top_token_given_prefix('<bos> I live in')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p( the | <bos> I live in ) = 0.20480634\n",
            "p( florida | <bos> I live in ) = 0.06449959\n",
            "p( california | <bos> I live in ) = 0.04631147\n",
            "p( a | <bos> I live in ) = 0.04002801\n",
            "p( your | <bos> I live in ) = 0.03340458\n",
            "p( my | <bos> I live in ) = 0.03132324\n",
            "p( texas | <bos> I live in ) = 0.02445643\n",
            "p( ny | <bos> I live in ) = 0.01626382\n",
            "p( canada | <bos> I live in ) = 0.01619168\n",
            "p( japan | <bos> I live in ) = 0.01268910\n",
            "p( chicago | <bos> I live in ) = 0.01215493\n",
            "p( new | <bos> I live in ) = 0.01203236\n",
            "p( portland | <bos> I live in ) = 0.01175667\n",
            "p( kansas | <bos> I live in ) = 0.01038384\n",
            "p( seattle | <bos> I live in ) = 0.00876120\n",
            "p( georgia | <bos> I live in ) = 0.00813357\n",
            "p( ohio | <bos> I live in ) = 0.00810098\n",
            "p( this | <bos> I live in ) = 0.00755778\n",
            "p( america | <bos> I live in ) = 0.00752445\n",
            "p( france | <bos> I live in ) = 0.00744124\n",
            "['the', 'florida', 'california', 'a', 'your', 'my', 'texas', 'ny', 'canada', 'japan', 'chicago', 'new', 'portland', 'kansas', 'seattle', 'georgia', 'ohio', 'this', 'america', 'france']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzGqlrKhbj_g"
      },
      "source": [
        "# Save the model\n",
        "# BE CAREFUL TO NOT OVERWRITE SOME IMPORTANT MODEL\n",
        "\n",
        "if False:\n",
        "    torch.save({\n",
        "        'options': options,\n",
        "        'loss_cache': plot_cache,\n",
        "        'model_dict': model.state_dict()\n",
        "    }, './static_files/persona_rnn_lm.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}